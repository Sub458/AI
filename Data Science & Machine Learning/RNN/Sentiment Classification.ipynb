{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664d78c4-9b8f-4ff8-b2d2-9a17220d37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e2d668-e3d4-4f8c-a0d8-828d131b8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dff855b-6ec7-4380-97bc-03b3a16384c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def addToken(token):\n",
    "    if token in vocab['t_2_i']:\n",
    "        idx =  vocab['t_2_i'][token]\n",
    "    else:\n",
    "        idx = len(vocab['t_2_i'])\n",
    "        vocab['t_2_i'][token] = idx\n",
    "        vocab['i_2_t'][idx] = token\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59409615-57f7-4562-9c27-3f44c2553982",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initializeVocabulary():\n",
    "    unkToken = '<UNK>'\n",
    "    vocab['t_2_i'] = {}\n",
    "    vocab['i_2_t'] = {}\n",
    "    idx = addToken(unkToken)\n",
    "    vocab['addUnk'] = True\n",
    "    vocab['unkToken'] = unkToken\n",
    "    vocab['unkTokenIdx'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938d4696-39d6-4c6f-bcb1-c22113d50a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addManyTokens(tokens):\n",
    "    idexs = [addToken(token) for token in tokens]\n",
    "    return idexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5b7279-1e7a-4f64-bfab-41867de46e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookuptoken(token):\n",
    "    if vocab['unkTokenIdx'] >= 0:\n",
    "        return vocab['t_2_i'].get(token,vocab['unkTokenIdx'])\n",
    "    else:\n",
    "        return vocab['t_2_i'][token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce77d23-68c4-496f-b5f2-40e9d8b75fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookupidx(idx):\n",
    "    if idx not in vocab['i_2_t']:\n",
    "        raise keyError(\"the index (%d) is not there\" %(idx))\n",
    "    return vocab['i_2_t'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a19f75a-421e-450f-bca0-c652e895a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cutoff in not more than 25 than don't add in vocabulary\n",
    "def vocabularyFromDataFrame(df,cutoff=25):\n",
    "    initializeVocabulary()\n",
    "    wordCounts = Counter()\n",
    "    for i in df.review:\n",
    "        for word in i.split(\" \"):\n",
    "            if word not in string.punctuation:\n",
    "                wordCounts[word] += 1\n",
    "    for word,count in wordCounts.items():\n",
    "        if count > cutoff:\n",
    "            addToken(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e45666-a424-4ce4-9d56-c5482d158439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Sub\\CodeSpace\\AI\\mastering_recurrent_neural_networks\\Data\\reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27850a6b-e470-41a0-b0fb-ce846a65a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabularyFromDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c4285cf-999f-49aa-bc73-e0e162280b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookuptoken('this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03fbae98-5df3-476d-8bca-cda44b50ba12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookupidx(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3ff6b6c-42d4-4466-a2a4-56e2410f0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(review):\n",
    "    isFirst = True\n",
    "    for token in review.split(\" \"):\n",
    "        if token not in string.punctuation:\n",
    "            oneHot = np.zeros((len(vocab['t_2_i']),1))\n",
    "            oneHot[lookuptoken(token)] = 1\n",
    "            if isFirst:\n",
    "                xF = oneHot\n",
    "                isFirst = False\n",
    "            else:\n",
    "                xF = np.hstack((xF,oneHot))\n",
    "    return xF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f05ada2-c66e-4ab6-a3f0-700ccc49df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "xF = vectorize(df['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ecf855-0be7-483d-8029-20b827257984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8945, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d025a97b-221b-476d-87bd-fa91e12f2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallDef_pos = df[df['rating']=='positive'].iloc[:5]\n",
    "smallDef_neg = df[df['rating']=='negative'].iloc[:5]\n",
    "df_small = pd.concat((smallDef_pos,smallDef_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa8a3df2-cdf5-4f54-855f-86d17986ec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>positive</td>\n",
       "      <td>my experience was by far the most pleasant i h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28001</th>\n",
       "      <td>positive</td>\n",
       "      <td>i have been to this place a couple of times on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28002</th>\n",
       "      <td>positive</td>\n",
       "      <td>very popular sushi bar in the heart of old tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28003</th>\n",
       "      <td>positive</td>\n",
       "      <td>the staff is nice . it s pretty clean . they u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28004</th>\n",
       "      <td>positive</td>\n",
       "      <td>my co worker picked up lunch for us from this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>terrible place to work for i just heard a stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>hours , minutes total time for an extremely s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my less than stellar review is for service . w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m granting one star because there s no way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>the food here is mediocre at best . i went aft...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review\n",
       "28000  positive  my experience was by far the most pleasant i h...\n",
       "28001  positive  i have been to this place a couple of times on...\n",
       "28002  positive  very popular sushi bar in the heart of old tow...\n",
       "28003  positive  the staff is nice . it s pretty clean . they u...\n",
       "28004  positive  my co worker picked up lunch for us from this ...\n",
       "0      negative  terrible place to work for i just heard a stor...\n",
       "1      negative   hours , minutes total time for an extremely s...\n",
       "2      negative  my less than stellar review is for service . w...\n",
       "3      negative  i m granting one star because there s no way t...\n",
       "4      negative  the food here is mediocre at best . i went aft..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf8d44df-9082-4eaf-903b-c2cd04246535",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabularyFromDataFrame(df_small,cutoff=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecbf4b0b-2979-41d0-b9a5-9ac11f2a1861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab['t_2_i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3adb3611-cf71-4ca0-88f6-1b41b9e42243",
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures = len(vocab['t_2_i'])\n",
    "numhiddenUnits = 10\n",
    "h0 = torch.tensor(np.zeros((numhiddenUnits,1)))\n",
    "Wx = torch.tensor(np.random.uniform(0,1,(numhiddenUnits,numFeatures)),requires_grad=True)\n",
    "Wh = torch.tensor(np.random.uniform(0,1,(numhiddenUnits,numhiddenUnits)),requires_grad=True)\n",
    "Wy = torch.tensor(np.random.uniform(0,1,(1,numhiddenUnits)),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec020dcb-1abe-4c45-ac33-25b11f55f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepForward(xt,Wx,Wh,Wy,prevMemory):\n",
    "    x_frd = torch.matmul(Wx,torch.from_numpy(xt[:,np.newaxis]))\n",
    "    h_frd = torch.matmul(Wh,prevMemory)\n",
    "    ht = torch.tanh(x_frd + h_frd)\n",
    "    y_hat = torch.sigmoid(torch.matmul(Wy,ht))\n",
    "    return ht,y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5f3d0b1-1122-4984-a0a1-3ad47553a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullForward(X,Wx,Wh,Wy,prevMemory):\n",
    "    y_hat = 0\n",
    "    for i in range(X.shape[1]):\n",
    "        ht,yhat = stepForward(X[:,i],Wx,Wh,Wy,prevMemory)\n",
    "        prevMemory = ht\n",
    "        y_hat = yhat\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8049cf0a-0222-4775-bbc3-b364aa5646d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLoss(y,y_hat):\n",
    "    loss = 0\n",
    "    for yi,yi_hat in zip(y,y_hat):\n",
    "        if yi == 1:\n",
    "            loss += -torch.log2(yi_hat)\n",
    "        else:\n",
    "            loss += -torch.log2(1-yi_hat)\n",
    "    return loss/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02ff7912-99c4-46d0-9d4e-ab9db5bb2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr):\n",
    "    with torch.no_grad():\n",
    "        Wx -= lr*dWx\n",
    "        Wy -= lr*dWy\n",
    "        Wh -= lr*dWh\n",
    "    return Wx,Wh,Wy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "420a71c1-ec32-49f7-91d8-b7b7e153b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRNN(train_df,Wx,Wh,Wy,prevMemory,lr,nepochs):\n",
    "    losses = []\n",
    "    for epoch in range(nepochs):\n",
    "        y,y_hat = [],[]\n",
    "        for rt,rv in zip(train_df['rating'],train_df['review']):\n",
    "            X = vectorize(rv)\n",
    "            yi_hat = fullForward(X,Wx,Wh,Wy,prevMemory)\n",
    "            yi = 0\n",
    "            if rt == 'positive':\n",
    "                yi = 1\n",
    "            y.append(yi)\n",
    "            y_hat.append(yi_hat)\n",
    "        loss = computeLoss(y,y_hat)\n",
    "        loss.backward()\n",
    "        losses.append(loss)\n",
    "        print(\"Loss after epoch %d : %f\" %(epoch,loss))\n",
    "        sys.stdout.flush()\n",
    "        dWx = Wx.grad.data\n",
    "        dWh = Wh.grad.data\n",
    "        dWy  = Wy.grad.data\n",
    "        Wx,Wh,Wy = updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr)\n",
    "        Wx.grad.data.zero_()\n",
    "        Wh.grad.data.zero_()\n",
    "        Wy.grad.data.zero_()\n",
    "    return Wx,Wh,Wy, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4710bf7c-ab63-4a92-8699-1f4f7e022516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0 : 2.620737\n",
      "Loss after epoch 1 : 2.574303\n",
      "Loss after epoch 2 : 2.528239\n",
      "Loss after epoch 3 : 2.482568\n",
      "Loss after epoch 4 : 2.437312\n",
      "Loss after epoch 5 : 2.392493\n",
      "Loss after epoch 6 : 2.348134\n",
      "Loss after epoch 7 : 2.304260\n",
      "Loss after epoch 8 : 2.260896\n",
      "Loss after epoch 9 : 2.218067\n",
      "Loss after epoch 10 : 2.175799\n",
      "Loss after epoch 11 : 2.134117\n",
      "Loss after epoch 12 : 2.093048\n",
      "Loss after epoch 13 : 2.052619\n",
      "Loss after epoch 14 : 2.012855\n",
      "Loss after epoch 15 : 1.973783\n",
      "Loss after epoch 16 : 1.935428\n",
      "Loss after epoch 17 : 1.897816\n",
      "Loss after epoch 18 : 1.860972\n",
      "Loss after epoch 19 : 1.824919\n",
      "Loss after epoch 20 : 1.789679\n",
      "Loss after epoch 21 : 1.755275\n",
      "Loss after epoch 22 : 1.721726\n",
      "Loss after epoch 23 : 1.689051\n",
      "Loss after epoch 24 : 1.657266\n",
      "Loss after epoch 25 : 1.626386\n",
      "Loss after epoch 26 : 1.596424\n",
      "Loss after epoch 27 : 1.567391\n",
      "Loss after epoch 28 : 1.539293\n",
      "Loss after epoch 29 : 1.512138\n",
      "Loss after epoch 30 : 1.485928\n",
      "Loss after epoch 31 : 1.460665\n",
      "Loss after epoch 32 : 1.436346\n",
      "Loss after epoch 33 : 1.412968\n",
      "Loss after epoch 34 : 1.390524\n",
      "Loss after epoch 35 : 1.369005\n",
      "Loss after epoch 36 : 1.348399\n",
      "Loss after epoch 37 : 1.328694\n",
      "Loss after epoch 38 : 1.309873\n",
      "Loss after epoch 39 : 1.291920\n",
      "Loss after epoch 40 : 1.274815\n",
      "Loss after epoch 41 : 1.258537\n",
      "Loss after epoch 42 : 1.243065\n",
      "Loss after epoch 43 : 1.228375\n",
      "Loss after epoch 44 : 1.214443\n",
      "Loss after epoch 45 : 1.201244\n",
      "Loss after epoch 46 : 1.188752\n",
      "Loss after epoch 47 : 1.176941\n",
      "Loss after epoch 48 : 1.165785\n",
      "Loss after epoch 49 : 1.155256\n"
     ]
    }
   ],
   "source": [
    "Wx,Wh,Wy, losses = trainRNN(df_small,Wx,Wh,Wy,h0,0.01,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ebba0d13-0df1-4bf2-9527-62449053457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = df_small['review'].iloc[9]\n",
    "y = df_small['rating'].iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5783f9d5-b9ef-4c0c-9ef2-4be622769ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorize(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84714120-865e-41f4-a658-bd214d9b984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = fullForward(X,Wx,Wh,Wy,h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8275e7f8-5111-43da-9660-fd6eeb0a9211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7136]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86d77b7c-091a-43c2-935f-8babad99e84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05044d43-674c-456e-b440-bfbeefd5398b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 7
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
