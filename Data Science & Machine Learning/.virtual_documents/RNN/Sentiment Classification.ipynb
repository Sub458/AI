import numpy as np
import pandas as pd
import torch
import sys
import string
from collections import Counter


vocab = {}


def addToken(token):
    if token in vocab['t_2_i']:
        idx =  vocab['t_2_i'][token]
    else:
        idx = len(vocab['t_2_i'])
        vocab['t_2_i'][token] = idx
        vocab['i_2_t'][idx] = token
    return idx


def initializeVocabulary():
    unkToken = '<UNK>'
    vocab['t_2_i'] = {}
    vocab['i_2_t'] = {}
    idx = addToken(unkToken)
    vocab['addUnk'] = True
    vocab['unkToken'] = unkToken
    vocab['unkTokenIdx'] = idx


def addManyTokens(tokens):
    idexs = [addToken(token) for token in tokens]
    return idexs


def lookuptoken(token):
    if vocab['unkTokenIdx'] >= 0:
        return vocab['t_2_i'].get(token,vocab['unkTokenIdx'])
    else:
        return vocab['t_2_i'][token]


def lookupidx(idx):
    if idx not in vocab['i_2_t']:
        raise keyError("the index (%d) is not there" %(idx))
    return vocab['i_2_t'][idx]


# if cutoff in not more than 25 than don't add in vocabulary
def vocabularyFromDataFrame(df,cutoff=25):
    initializeVocabulary()
    wordCounts = Counter()
    for i in df.review:
        for word in i.split(" "):
            if word not in string.punctuation:
                wordCounts[word] += 1
    for word,count in wordCounts.items():
        if count > cutoff:
            addToken(word)


df = pd.read_csv(r"C:\Users\Sub\CodeSpace\AI\mastering_recurrent_neural_networks\Data\reviews.csv")


vocabularyFromDataFrame(df)


lookuptoken('this')


lookupidx(128)


def vectorize(review):
    isFirst = True
    for token in review.split(" "):
        if token not in string.punctuation:
            oneHot = np.zeros((len(vocab['t_2_i']),1))
            oneHot[lookuptoken(token)] = 1
            if isFirst:
                xF = oneHot
                isFirst = False
            else:
                xF = np.hstack((xF,oneHot))
    return xF


xF = vectorize(df['review'][1])


xF.shape


smallDef_pos = df[df['rating']=='positive'].iloc[:5]
smallDef_neg = df[df['rating']=='negative'].iloc[:5]
df_small = pd.concat((smallDef_pos,smallDef_neg))


df_small


vocabularyFromDataFrame(df_small,cutoff=0)


len(vocab['t_2_i'])


numFeatures = len(vocab['t_2_i'])
numhiddenUnits = 10
h0 = torch.tensor(np.zeros((numhiddenUnits,1)))
Wx = torch.tensor(np.random.uniform(0,1,(numhiddenUnits,numFeatures)),requires_grad=True)
Wh = torch.tensor(np.random.uniform(0,1,(numhiddenUnits,numhiddenUnits)),requires_grad=True)
Wy = torch.tensor(np.random.uniform(0,1,(1,numhiddenUnits)),requires_grad=True)


def stepForward(xt,Wx,Wh,Wy,prevMemory):
    x_frd = torch.matmul(Wx,torch.from_numpy(xt[:,np.newaxis]))
    h_frd = torch.matmul(Wh,prevMemory)
    ht = torch.tanh(x_frd + h_frd)
    y_hat = torch.sigmoid(torch.matmul(Wy,ht))
    return ht,y_hat


def fullForward(X,Wx,Wh,Wy,prevMemory):
    y_hat = 0
    for i in range(X.shape[1]):
        ht,yhat = stepForward(X[:,i],Wx,Wh,Wy,prevMemory)
        prevMemory = ht
        y_hat = yhat
    return y_hat


def computeLoss(y,y_hat):
    loss = 0
    for yi,yi_hat in zip(y,y_hat):
        if yi == 1:
            loss += -torch.log2(yi_hat)
        else:
            loss += -torch.log2(1-yi_hat)
    return loss/len(y)


def updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr):
    with torch.no_grad():
        Wx -= lr*dWx
        Wy -= lr*dWy
        Wh -= lr*dWh
    return Wx,Wh,Wy


def trainRNN(train_df,Wx,Wh,Wy,prevMemory,lr,nepochs):
    losses = []
    for epoch in range(nepochs):
        y,y_hat = [],[]
        for rt,rv in zip(train_df['rating'],train_df['review']):
            X = vectorize(rv)
            yi_hat = fullForward(X,Wx,Wh,Wy,prevMemory)
            yi = 0
            if rt == 'positive':
                yi = 1
            y.append(yi)
            y_hat.append(yi_hat)
        loss = computeLoss(y,y_hat)
        loss.backward()
        losses.append(loss)
        print("Loss after epoch %d : %f" %(epoch,loss))
        sys.stdout.flush()
        dWx = Wx.grad.data
        dWh = Wh.grad.data
        dWy  = Wy.grad.data
        Wx,Wh,Wy = updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr)
        Wx.grad.data.zero_()
        Wh.grad.data.zero_()
        Wy.grad.data.zero_()
    return Wx,Wh,Wy, losses


Wx,Wh,Wy, losses = trainRNN(df_small,Wx,Wh,Wy,h0,0.01,50)


v = df_small['review'].iloc[9]
y = df_small['rating'].iloc[9]


X = vectorize(v)


y_hat = fullForward(X,Wx,Wh,Wy,h0)


y_hat


y



